{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f7de0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# !!!THESE ARE ONLY USED TO DOWNLOAD THE MNIST DATASET!!!\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbc63d",
   "metadata": {},
   "source": [
    "Downloading the dataset using keras cause it handles unpacking well and manually doing it would be a headache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "653ef96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556159b5",
   "metadata": {},
   "source": [
    "### Analysing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a818b263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60000, 28, 28)\n",
      "Test set shape: (10000, 28, 28)\n",
      "Unique labels in training set: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Test set shape:\", x_test.shape)\n",
    "print(\"Unique labels in training set:\", np.unique(y_train))\n",
    "\n",
    "plt.imshow(x_train[0], cmap='bone')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85117ef5",
   "metadata": {},
   "source": [
    "so we have about `60,000 training` images and `10,000 test` images of size `28x28` pixels with labels 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b452901",
   "metadata": {},
   "source": [
    "### Making the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "855b9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, weights: list[float], bias:float):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def calc_sum(self, input_neuron: list[float]) -> list:\n",
    "        values = np.zeros(len(self.weights))\n",
    "\n",
    "        for w in range(len(self.weights)):\n",
    "            r = input_neuron[w]*self.weights[w]\n",
    "            values[w] = r\n",
    "        return values, np.sum(values)\n",
    "    \n",
    "    def activate(self, summation:float, act_func) -> float:\n",
    "        return act_func(summation) + self.bias\n",
    "    \n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, neurons: list[Neuron], act_func):\n",
    "        self.neurons = neurons\n",
    "        self.act_func = act_func\n",
    "    \n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        gen_out = np.zeros(len(self.neurons))\n",
    "        \n",
    "        for n, neuron in enumerate(self.neurons):\n",
    "            summation = neuron.calc_sum(inputs)[1]\n",
    "            gen_out[n] = neuron.activate(summation=summation, act_func=self.act_func)\n",
    "        return gen_out\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers: list[Layer]):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        output = inputs\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def predict(self, x_input: np.ndarray, y_input: int, index: int) -> list:\n",
    "        inputs = x_input[index]\n",
    "        output = self.forward(inputs)\n",
    "        predicted = int(np.argmax(output))\n",
    "        actual = y_input[index]\n",
    "        return predicted, actual\n",
    "    \n",
    "    def evaluate(self, x_data: np.ndarray, y_data: np.ndarray, limit: int = None) -> float:\n",
    "        correct = 0\n",
    "        total = min(limit, len(x_data)) if limit else len(x_data)\n",
    "        for i in range(total):\n",
    "            if self.predict(x_data, y_data, i)[0] == y_data[i]:\n",
    "                correct += 1\n",
    "        return correct / total\n",
    "    \n",
    "    def save_weights(self, path: str = 'weights') -> None:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            weights = [n.weights for n in layer.neurons]\n",
    "            np.savetxt(f'{path}/w_layer{i+1}.txt', weights)\n",
    "\n",
    "\n",
    "#  ---------- Activation Functions -------------\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x: float) -> float:\n",
    "    return np.maximum(0, x)\n",
    "    \n",
    "\n",
    "# ---------- Data related functions ----------\n",
    "\n",
    "def flatten_data(x_train: np.ndarray) -> list:\n",
    "    flattened_x_images = []\n",
    "\n",
    "    for i in x_train:\n",
    "        flattened_x_images.append(i.flatten())\n",
    "    \n",
    "    return flattened_x_images\n",
    "\n",
    "\n",
    "def get_rand_weights(no_neurons: int) -> list:\n",
    "    return [random.uniform(-0.1, 0.1) for _ in range(no_neurons)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44a8613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input_layer = flatten_data(x_train)\n",
    "initial_input_layer = np.array(initial_input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741759d0",
   "metadata": {},
   "source": [
    "#### Build and Test out the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d204773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 5\n",
      "Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "NUM_INPUTS = initial_input_layer.shape[1]\n",
    "NUM_NEURONS = 16\n",
    "OUTPUT_NEURONS = len(np.unique(y_train))\n",
    "\n",
    "\"\"\"\n",
    "Neuron Input: List[weights], bias\n",
    "Layer Input: List[Neurons], Activation_Function\n",
    "\"\"\"\n",
    "network = Network(layers=[\n",
    "    Layer([Neuron(get_rand_weights(NUM_INPUTS), 0.0) for _ in range(NUM_NEURONS)], act_func=relu),\n",
    "    Layer([Neuron(get_rand_weights(NUM_NEURONS), 0.0) for _ in range(NUM_NEURONS)], act_func=relu),\n",
    "    Layer([Neuron(get_rand_weights(NUM_NEURONS), 0.0) for _ in range(OUTPUT_NEURONS)], act_func=sigmoid),\n",
    "])\n",
    "\n",
    "# Single prediction\n",
    "prediction, actual = network.predict(initial_input_layer, y_train, 0)\n",
    "\n",
    "print(prediction, actual)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = network.evaluate(initial_input_layer, y_train, limit=50)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "\n",
    "# Save weights\n",
    "network.save_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88694efc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e88000",
   "metadata": {},
   "source": [
    "# Fasion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06287550",
   "metadata": {},
   "source": [
    "### Using the Fashion Dataset as alternative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa084c5",
   "metadata": {},
   "source": [
    "| Label | Description |\n",
    "| :--- | :--- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b480a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xf_train, yf_train), (xf_test, yf_test) = keras.datasets.fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "858a5faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60000, 28, 28)\n",
      "Test set shape: (10000, 28, 28)\n",
      "Unique labels in training set: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training set shape:\", xf_train.shape)\n",
    "print(\"Test set shape:\", xf_test.shape)\n",
    "print(\"Unique labels in training set:\", np.unique(yf_train))\n",
    "\n",
    "plt.imshow(xf_train[0], cmap='bone')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce99210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_input_layer_f = flatten_data(xf_train)\n",
    "initial_input_layer_f = np.array(initial_input_layer_f)\n",
    "initial_input_layer_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8e222be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 9\n",
      "Accuracy: 8.00%\n"
     ]
    }
   ],
   "source": [
    "NUM_INPUTS = initial_input_layer_f.shape[1]\n",
    "NUM_NEURONS = 16\n",
    "OUTPUT_NEURONS = len(np.unique(yf_train))\n",
    "\n",
    "\"\"\"\n",
    "Neuron Input: List[weights], bias\n",
    "Layer Input: List[Neurons], Activation_Function\n",
    "\"\"\"\n",
    "network_fashion = Network(layers=[\n",
    "    Layer([Neuron(get_rand_weights(NUM_INPUTS), 0.0) for _ in range(NUM_NEURONS)], act_func=relu),\n",
    "    Layer([Neuron(get_rand_weights(NUM_NEURONS), 0.0) for _ in range(NUM_NEURONS)], act_func=relu),\n",
    "    Layer([Neuron(get_rand_weights(NUM_NEURONS), 0.0) for _ in range(OUTPUT_NEURONS)], act_func=sigmoid),\n",
    "])\n",
    "\n",
    "# Single prediction\n",
    "prediction_fasion, actual_fasion = network.predict(initial_input_layer_f, yf_train, 0)\n",
    "\n",
    "print(prediction_fasion, actual_fasion)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_fasion = network_fashion.evaluate(initial_input_layer_f, yf_train, limit=50)\n",
    "print(f'Accuracy: {accuracy_fasion:.2%}')\n",
    "\n",
    "# Save weights\n",
    "network_fashion.save_weights(path='weights_fasion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38c525",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sem8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
